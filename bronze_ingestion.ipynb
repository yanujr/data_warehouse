{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d17fdc77-42b8-4ca8-88e5-2e3ba9a5da36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing entity: cust_info\nSource path: /Volumes/data_warehouse/source/crm/cust_info.csv\nTarget table: data_warehouse.bronze.cust_info\n✅ Loaded 18494 rows from cust_info.csv\n------------------------------\nProcessing entity: prd_info\nSource path: /Volumes/data_warehouse/source/crm/prd_info.csv\nTarget table: data_warehouse.bronze.prd_info\n✅ Loaded 397 rows from prd_info.csv\n------------------------------\nProcessing entity: sales_details\nSource path: /Volumes/data_warehouse/source/crm/sales_details.csv\nTarget table: data_warehouse.bronze.sales_details\n✅ Loaded 60398 rows from sales_details.csv\n------------------------------\nProcessing entity: CUST_AZ12\nSource path: /Volumes/data_warehouse/source/erp/CUST_AZ12.csv\nTarget table: data_warehouse.bronze.CUST_AZ12\n✅ Loaded 18484 rows from CUST_AZ12.csv\n------------------------------\nProcessing entity: LOC_A101\nSource path: /Volumes/data_warehouse/source/erp/LOC_A101.csv\nTarget table: data_warehouse.bronze.LOC_A101\n✅ Loaded 18484 rows from LOC_A101.csv\n------------------------------\nProcessing entity: PX_CAT_G1V2\nSource path: /Volumes/data_warehouse/source/erp/PX_CAT_G1V2.csv\nTarget table: data_warehouse.bronze.PX_CAT_G1V2\n✅ Loaded 37 rows from PX_CAT_G1V2.csv\n------------------------------\n"
     ]
    }
   ],
   "source": [
    "sources = {\n",
    "    \"crm\": ['cust_info', 'prd_info', 'sales_details'],\n",
    "    \"erp\": ['CUST_AZ12', 'LOC_A101', 'PX_CAT_G1V2']\n",
    "}\n",
    "\n",
    "for source_type, entities in sources.items():\n",
    "    for entity in entities:\n",
    "        source_dir = f'/Volumes/data_warehouse/source/{source_type}/{entity}.csv'\n",
    "        target_table = f'data_warehouse.bronze.{entity}'\n",
    "        \n",
    "        print(f\"Processing entity: {entity}\")\n",
    "        print(f\"Source path: {source_dir}\")\n",
    "        print(f\"Target table: {target_table}\")\n",
    "        \n",
    "\n",
    "        # Read CSV\n",
    "        df = spark.read.format('csv') \\\n",
    "                        .option('header', True) \\\n",
    "                        .option('inferSchema', True) \\\n",
    "                        .load(source_dir)\n",
    "\n",
    "        row_count = df.count()\n",
    "        print(f\"✅ Loaded {row_count} rows from {entity}.csv\")\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        # Truncate Table\n",
    "        spark.sql(f'TRUNCATE TABLE {target_table}')\n",
    "\n",
    "        # Write to Delta table\n",
    "        df.write.format('delta') \\\n",
    "                .mode('append') \\\n",
    "                .option('overwriteSchema', True) \\\n",
    "                .saveAsTable(target_table)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6091477281504317,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}